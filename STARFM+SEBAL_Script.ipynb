{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STARFM+SEBAL Script.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wR0RpB_aovn0",
        "tHckdGnDkYNR",
        "uPFxcOuLpEg3",
        "KHECz120park",
        "BtAPcG-5pu08",
        "Q5beygKep1hW",
        "wMq1UJOop6Ox",
        "T37dITPyp-_8",
        "W0ODIMR0obK0"
      ],
      "toc_visible": true,
      "mount_file_id": "1dixT0wIYVhata-p7UXE6pV73QdQonH8K",
      "authorship_tag": "ABX9TyPEgju9EafkTkseys8fPEWx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thomasmcz/evapotranspiration/blob/main/STARFM%2BSEBAL_Script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR0RpB_aovn0"
      },
      "source": [
        "# INITIALIZING EE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEJuS1yViuow"
      },
      "source": [
        "# Import Earth Engine Library\n",
        "import ee\n",
        " \n",
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        " \n",
        "# Initialize the library.\n",
        "ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHckdGnDkYNR"
      },
      "source": [
        "# Importing libraries and defining functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxntkBSZg8gK"
      },
      "source": [
        "# Import some essencial libraries and define the functions for focal analyses (make_slices) and image export (make_raster)\n",
        " \n",
        "import numpy as np\n",
        "from osgeo import gdal\n",
        "import os\n",
        "import math\n",
        " \n",
        "os.chdir(r\"/content/drive/MyDrive\")\n",
        "\n",
        "# The next two functions were obtained from \"Geoprocessing with Python\" book, by Chris Garrard\n",
        "# It is available from https://www.manning.com/books/geoprocessing-with-python?query=geoprocessing\n",
        "def make_slices(data, win_size):\n",
        "    \"\"\"Return a list of slices given a window size.\n",
        "    data     - two-dimensional array to get slices from\n",
        "    win_size - tuple of (rows, columns) for the moving window\"\"\"\n",
        "    rows = data.shape[0] - win_size[0] + 1\n",
        "    cols = data.shape[1] - win_size[1] + 1\n",
        "    slices = []\n",
        "    for i in range(win_size[0]):\n",
        "        for j in range(win_size[1]):\n",
        "            slices.append(data[i:rows+i, j:cols+j])\n",
        "    return slices\n",
        " \n",
        "def make_raster(in_ds, fn, data, data_type, nodata=None):\n",
        "    \"\"\"Create a one-band GeoTIFF.\n",
        "    in_ds - datasource to copy projection and geotransform from\n",
        "    fn - path to the file to create\n",
        "    data - NumPy array containing data to write\n",
        "    data_type - output data type\n",
        "    nodata - optional NoData value\"\"\"\n",
        "    driver = gdal.GetDriverByName('GTiff')\n",
        "    out_ds = driver.Create(fn, in_ds.RasterXSize, in_ds.RasterYSize, 1, data_type)\n",
        "    out_ds.SetProjection(in_ds.GetProjection())\n",
        "    out_ds.SetGeoTransform(in_ds.GetGeoTransform())\n",
        "    out_band = out_ds.GetRasterBand(1)\n",
        "    if nodata is not None:\n",
        "        out_band.SetNoDataValue(nodata)\n",
        "    out_band.WriteArray(data)\n",
        "    out_band.FlushCache()\n",
        "    out_band.ComputeStatistics(False)\n",
        "    return out_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPFxcOuLpEg3"
      },
      "source": [
        "# Exporting MODIS images to your drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJHnG3lujIBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f85f1b6-0a38-4891-a4f0-3091d54bdc3e"
      },
      "source": [
        "# Define your study area\n",
        "mandacaru = ee.Geometry.Polygon(\n",
        "        [[[-40.443765656859135, -9.369681936878271],\n",
        "          [-40.443765656859135, -9.4184573955032],\n",
        "          [-40.38179589977906, -9.4184573955032],\n",
        "          [-40.38179589977906, -9.369681936878271]]])\n",
        "\n",
        "#Choose the dates of the MODIS images that will be processed in the STARFM algorithm\n",
        "data1 = ee.String('2016_10_29')\n",
        "data2 = ee.String('2016_12_31')\n",
        "data3 = ee.String('2017_01_17')\n",
        "\n",
        "nome_gq = ee.String('MODIS/006/MYD09GQ/')\n",
        "nome_a1 = ee.String('MODIS/006/MYD11A1/')\n",
        "nome_a3 = ee.String('MODIS/006/MCD43A3/')\n",
        "\n",
        "pegar_gq_1 = nome_gq.cat(data1)\n",
        "pegar_gq_2 = nome_gq.cat(data2)\n",
        "pegar_gq_3 = nome_gq.cat(data3)\n",
        "\n",
        "pegar_a1_1 = nome_a1.cat(data1)\n",
        "pegar_a1_2 = nome_a1.cat(data2)\n",
        "pegar_a1_3 = nome_a1.cat(data3)\n",
        "\n",
        "pegar_a3_1 = nome_a3.cat(data1)\n",
        "pegar_a3_2 = nome_a3.cat(data2)\n",
        "pegar_a3_3 = nome_a3.cat(data3)\n",
        "\n",
        "img1 = ee.Image(pegar_gq_1.getInfo())\n",
        "img2 = ee.Image(pegar_gq_2.getInfo())\n",
        "img3 = ee.Image(pegar_gq_3.getInfo())\n",
        "\n",
        "img4 = ee.Image(pegar_a1_1.getInfo())\n",
        "img5 = ee.Image(pegar_a1_2.getInfo())\n",
        "img6 = ee.Image(pegar_a1_3.getInfo())\n",
        "\n",
        "img7 = ee.Image(pegar_a3_1.getInfo())\n",
        "img8 = ee.Image(pegar_a3_2.getInfo())\n",
        "img9 = ee.Image(pegar_a3_3.getInfo())\n",
        "\n",
        "img_export1 = img1.select(['sur_refl_b01', 'sur_refl_b02']).multiply(0.0001)\n",
        "img_export2 = img2.select(['sur_refl_b01', 'sur_refl_b02']).multiply(0.0001)\n",
        "img_export3 = img3.select(['sur_refl_b01', 'sur_refl_b02']).multiply(0.0001)\n",
        "\n",
        "img_export4 = img4.select(['LST_Day_1km']).multiply(0.02)\n",
        "img_export5 = img5.select(['LST_Day_1km']).multiply(0.02)\n",
        "img_export6 = img6.select(['LST_Day_1km']).multiply(0.02)\n",
        "\n",
        "img_export7 = img7.select(['Albedo_BSA_shortwave']).multiply(0.001)\n",
        "img_export8 = img8.select(['Albedo_BSA_shortwave']).multiply(0.001)\n",
        "img_export9 = img9.select(['Albedo_BSA_shortwave']).multiply(0.001)\n",
        "\n",
        "produto_1 = ee.String('modis_gq')\n",
        "produto_2 = ee.String('modis_a1')\n",
        "produto_3 = ee.String('modis_a3')\n",
        "\n",
        "saida_1 = produto_1.cat(data1)\n",
        "saida_2 = produto_1.cat(data2)\n",
        "saida_3 = produto_1.cat(data3)\n",
        "\n",
        "saida_4 = produto_2.cat(data1)\n",
        "saida_5 = produto_2.cat(data2)\n",
        "saida_6 = produto_2.cat(data3)\n",
        "\n",
        "saida_7 = produto_3.cat(data1)\n",
        "saida_8 = produto_3.cat(data2)\n",
        "saida_9 = produto_3.cat(data3)\n",
        "\n",
        "task1 = ee.batch.Export.image.toDrive(image=img_export1, folder='colab_imagens', description='modis', scale=30, region=mandacaru, fileNamePrefix=saida_1.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "task2 = ee.batch.Export.image.toDrive(image=img_export2, folder='colab_imagens', description='modis', scale=30, region=mandacaru, fileNamePrefix=saida_2.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "task3 = ee.batch.Export.image.toDrive(image=img_export3, folder='colab_imagens', description='modis', scale=30, region=mandacaru, fileNamePrefix=saida_3.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "task4 = ee.batch.Export.image.toDrive(image=img_export4, folder='colab_imagens', description='modis', scale=30, region=mandacaru, fileNamePrefix=saida_4.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "task5 = ee.batch.Export.image.toDrive(image=img_export5, folder='colab_imagens', description='modis', scale=30, region=mandacaru, fileNamePrefix=saida_5.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "task6 = ee.batch.Export.image.toDrive(image=img_export6, folder='colab_imagens', description='modis', scale=30, region=mandacaru, fileNamePrefix=saida_6.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "task7 = ee.batch.Export.image.toDrive(image=img_export7, folder='colab_imagens', description='modis', scale=30, region=mandacaru, fileNamePrefix=saida_7.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "task8 = ee.batch.Export.image.toDrive(image=img_export8, folder='colab_imagens', description='modis', scale=30, region=mandacaru, fileNamePrefix=saida_8.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "task9 = ee.batch.Export.image.toDrive(image=img_export9, folder='colab_imagens', description='modis', scale=30, region=mandacaru, fileNamePrefix=saida_9.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "\n",
        "task1.start()\n",
        "task1.status()\n",
        "\n",
        "task2.start()\n",
        "task2.status()\n",
        "\n",
        "task3.start()\n",
        "task3.status()\n",
        "\n",
        "task4.start()\n",
        "task4.status()\n",
        "\n",
        "task5.start()\n",
        "task5.status()\n",
        "\n",
        "task6.start()\n",
        "task6.status()\n",
        "\n",
        "task7.start()\n",
        "task7.status()\n",
        "\n",
        "task8.start()\n",
        "task8.status()\n",
        "\n",
        "task9.start()\n",
        "task9.status()\n",
        "\n",
        "print('End of the Script')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fim do Script\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHECz120park"
      },
      "source": [
        "# Exporting Landsat-8 images to your drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRKq4ZvsrJ9m"
      },
      "source": [
        "# Define your study area\n",
        "mandacaru = ee.Geometry.Polygon(\n",
        "        [[[-40.443765656859135, -9.369681936878271],\n",
        "          [-40.443765656859135, -9.4184573955032],\n",
        "          [-40.38179589977906, -9.4184573955032],\n",
        "          [-40.38179589977906, -9.369681936878271]]])\n",
        "\n",
        "#Choose the dates of the Landsat images that will be processed in the STARFM algorithm\n",
        "data1 = ee.String('2016_10_29')\n",
        "data2 = ee.String('2017_01_17')\n",
        "\n",
        "# Change the dates in the .filterDate method by adding the day that you want, following by the next day\n",
        "img = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').filterDate('2016-10-29', '2016-10-30').filterBounds(mandacaru)\n",
        "img = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').filterDate('2016-10-29', '2016-10-30').filterBounds(mandacaru)\n",
        "img2 = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').filterDate('2017-01-17', '2017-01-18').filterBounds(mandacaru)\n",
        "raw = ee.ImageCollection('LANDSAT/LC08/C01/T1').filterDate('2016-10-29', '2016-10-30').filterBounds(mandacaru)\n",
        "raw2 = ee.ImageCollection('LANDSAT/LC08/C01/T1').filterDate('2017-01-17', '2017-01-18').filterBounds(mandacaru)\n",
        "\n",
        "mosaico = img.mosaic()\n",
        "mosaico2 = img2.mosaic()\n",
        "\n",
        "surface_reflectance = mosaico.select(['B2', 'B3', 'B4', 'B5', 'B6', 'B7']).multiply(0.0001)\n",
        "surface_reflectance2 = mosaico2.select(['B2', 'B3', 'B4', 'B5', 'B6', 'B7']).multiply(0.0001)\n",
        "albedo = surface_reflectance.expression(\n",
        "    '(0.2453*B2) + (0.0508*B3) + (0.1804*B4) + (0.3081*B5) + (0.1332*B6) + (0.0521*B7) + 0.0011',{'B2': surface_reflectance.select('B2'),'B3': surface_reflectance.select('B3'),'B4': surface_reflectance.select('B4'),'B5': surface_reflectance.select('B5'),'B6': surface_reflectance.select('B6'),'B7': surface_reflectance.select('B7'),})\n",
        "albedo2 = surface_reflectance2.expression(\n",
        "    '(0.2453*B2) + (0.0508*B3) + (0.1804*B4) + (0.3081*B5) + (0.1332*B6) + (0.0521*B7) + 0.0011',{'B2': surface_reflectance2.select('B2'),'B3': surface_reflectance2.select('B3'),'B4': surface_reflectance2.select('B4'),'B5': surface_reflectance2.select('B5'),'B6': surface_reflectance2.select('B6'),'B7': surface_reflectance2.select('B7'),})\n",
        "\n",
        "add = ee.Number(raw.aggregate_mean('RADIANCE_ADD_BAND_10'))\n",
        "mult = ee.Number(raw.aggregate_mean('RADIANCE_MULT_BAND_10'))\n",
        "\n",
        "add2 = ee.Number(raw2.aggregate_mean('RADIANCE_ADD_BAND_10'))\n",
        "mult2 = ee.Number(raw2.aggregate_mean('RADIANCE_MULT_BAND_10'))\n",
        "\n",
        "mosaico_raw = raw.mosaic()\n",
        "mosaico_raw2 = raw2.mosaic()\n",
        "\n",
        "rad = mosaico_raw.expression('add + mult * nd',{'add': add, 'mult': mult, 'nd': mosaico_raw.select('B10')})\n",
        "rad2 = mosaico_raw2.expression('add + mult * nd',{'add': add2, 'mult': mult2, 'nd': mosaico_raw2.select('B10')})\n",
        "\n",
        "elevacao = raw.aggregate_mean('SUN_ELEVATION')\n",
        "elevacao2 = raw2.aggregate_mean('SUN_ELEVATION')\n",
        "\n",
        "#print('The average of the elevations is: ', elevacao)\n",
        "\n",
        "cos_z = ee.Number(elevacao).multiply(math.pi).divide(180).sin()\n",
        "cos_z2 = ee.Number(elevacao2).multiply(math.pi).divide(180).sin()\n",
        "\n",
        "#print ('The sin(E) is: ', cos_z)\n",
        "\n",
        "dt_s = raw.aggregate_mean('EARTH_SUN_DISTANCE')\n",
        "dt_s2 = raw2.aggregate_mean('EARTH_SUN_DISTANCE')\n",
        "\n",
        "#print('The Earth-Sun Distance is: ', dt_s)\n",
        "dr = ee.Number(1).divide((ee.Number(dt_s)).pow(2))\n",
        "dr2 = ee.Number(1).divide((ee.Number(dt_s2)).pow(2))\n",
        "\n",
        "#print ('dr is: ', dr)\n",
        "\n",
        "reflectance_toa = mosaico_raw.expression('(-0.10000000149011612 + 0.000019999999494757503 * nd) / (cos_z * dr)',{'nd': mosaico_raw,'cos_z': cos_z, 'dr': dr})\n",
        "reflectance_toa2 = mosaico_raw2.expression('(-0.10000000149011612 + 0.000019999999494757503 * nd) / (cos_z * dr)',{'nd': mosaico_raw2,'cos_z': cos_z2, 'dr': dr2})\n",
        "\n",
        "savi = reflectance_toa.expression('(1.1 * (NIR - RED)) / (0.1 + NIR + RED)',{'NIR': reflectance_toa.select('B5'), 'RED': reflectance_toa.select('B4'),})\n",
        "\n",
        "savi2 = reflectance_toa2.expression('(1.1 * (NIR - RED)) / (0.1 + NIR + RED)',{'NIR': reflectance_toa2.select('B5'), 'RED': reflectance_toa2.select('B4'),})\n",
        "\n",
        "iaf = savi.where(savi.lt(0.688000), savi.expression('(log((0.69 - savi) / 0.59)) * (-1) / 0.91',{'savi': savi.select('constant'),}))\n",
        "iaf2 = iaf.where(savi.gt(0.688000), 6)\n",
        "iafcorrigido = iaf2.where(savi.lt(0.000001), 0)\n",
        "\n",
        "iaf_2 = savi2.where(savi2.lt(0.688000), savi2.expression('(log((0.69 - savi) / 0.59)) * (-1) / 0.91',{'savi': savi2.select('constant'),}))\n",
        "iaf2_2 = iaf_2.where(savi2.gt(0.688000), 6)\n",
        "iafcorrigido_2 = iaf2_2.where(savi2.lt(0.000001), 0)\n",
        "\n",
        "e_nb = iafcorrigido.expression('0.97 + (0.0033 * iaf)', {'iaf': iafcorrigido.select('constant')})\n",
        "e_nb2 = e_nb.where(iafcorrigido.gt(2.999999), 0.98)\n",
        "e_nbcorrigido = e_nb2.where(iafcorrigido.lt(0.000001), 0.99)\n",
        "\n",
        "e_nb_2 = iafcorrigido_2.expression('0.97 + (0.0033 * iaf)', {'iaf': iafcorrigido_2.select('constant')})\n",
        "e_nb2_2 = e_nb_2.where(iafcorrigido_2.gt(2.999999), 0.98)\n",
        "e_nbcorrigido2 = e_nb2_2.where(iafcorrigido_2.lt(0.000001), 0.99)\n",
        "\n",
        "tsup = rad.expression('1321.08 / log(774.89 * e_nb / (radiance - 0.29) + 1)', {'e_nb': e_nbcorrigido.select('constant'), 'radiance': rad})\n",
        "tsup2 = rad.expression('1321.08 / log(774.89 * e_nb / (radiance - 0.29) + 1)', {'e_nb': e_nbcorrigido2.select('constant'), 'radiance': rad2})\n",
        "\n",
        "imagem_1 = ee.String('reflectance_')\n",
        "imagem_2 = ee.String('albedo_')\n",
        "imagem_3 = ee.String('tsup_')\n",
        "\n",
        "saida_1 = imagem_1.cat(data1)\n",
        "saida_2 = imagem_1.cat(data2)\n",
        "saida_3 = imagem_2.cat(data1)\n",
        "saida_4 = imagem_2.cat(data2)\n",
        "saida_5 = imagem_3.cat(data1)\n",
        "saida_6 = imagem_3.cat(data2)\n",
        "\n",
        "task1 = ee.batch.Export.image.toDrive(image=surface_reflectance, folder='colab_imagens', description='Landsat', scale=30, region=mandacaru, fileNamePrefix=saida_1.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "task2 = ee.batch.Export.image.toDrive(image=surface_reflectance2, folder='colab_imagens', description='Landsat', scale=30, region=mandacaru, fileNamePrefix=saida_2.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "\n",
        "task3 = ee.batch.Export.image.toDrive(image=albedo, folder='colab_imagens', description='Landsat', scale=30, region=mandacaru, fileNamePrefix=saida_3.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "task4 = ee.batch.Export.image.toDrive(image=albedo2, folder='colab_imagens', description='Landsat', scale=30, region=mandacaru, fileNamePrefix=saida_4.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "\n",
        "task5 = ee.batch.Export.image.toDrive(image=tsup, folder='colab_imagens', description='Landsat', scale=30, region=mandacaru, fileNamePrefix=saida_5.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "task6 = ee.batch.Export.image.toDrive(image=tsup2, folder='colab_imagens', description='Landsat', scale=30, region=mandacaru, fileNamePrefix=saida_6.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "\n",
        "task1.start()\n",
        "task2.start()\n",
        "task3.start()\n",
        "task4.start()\n",
        "task5.start()\n",
        "task6.start()\n",
        "print('End of the Script')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtAPcG-5pu08"
      },
      "source": [
        "# STARFM PART I"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIscJP54eMxh"
      },
      "source": [
        "# This script selects the Spectrally Similar Neighbor Pixels and exports them with Euclidean distance information.\n",
        "\n",
        "# Define the directory that has the images to be processed.\n",
        "os.chdir(r\"/content/drive/MyDrive/colab_imagens\")\n",
        "\n",
        "in_ds = gdal.Open('reflectance_2016_10_29.tif')# Load the first LANDSAT image (the day before the predicted date)\n",
        "in_band_lv = in_ds.GetRasterBand(3) # Get the red band\n",
        "in_band_liv = in_ds.GetRasterBand(4)  # Get the IR band\n",
        "\n",
        "in_ds_mv = gdal.Open('modis_gq2016_10_29.tif') # Load the first MODIS image (the day before the predicted date)\n",
        "in_band_mv = in_ds_mv.GetRasterBand(1) # Get the red band\n",
        "in_band_miv = in_ds_mv.GetRasterBand(2) # Get the IR band\n",
        "\n",
        "in_ds_k2 = gdal.Open('reflectance_2017_01_17.tif')# Load the second LANDSAT image (the day after the predicted date)\n",
        "in_band_lv_k2 = in_ds_k2.GetRasterBand(3) # Get the red band\n",
        "in_band_liv_k2 = in_ds_k2.GetRasterBand(4) # Get the red band\n",
        "\n",
        "in_ds_mv_k2 = gdal.Open('modis_gq2017_01_17.tif') # Load the second MODIS image (the day after the predicted date)\n",
        "in_band_mv_k2 = in_ds_mv_k2.GetRasterBand(1) # Get the red band\n",
        "in_band_miv_k2 = in_ds_mv_k2.GetRasterBand(2) # Get the IR band\n",
        "\n",
        "in_ds_mv_ko = gdal.Open('modis_gq2016_12_31.tif') # Load the third MODIS image (predicted date)\n",
        "in_band_mv_ko = in_ds_mv_ko.GetRasterBand(1) # Get the red band\n",
        "in_band_miv_ko = in_ds_mv_ko.GetRasterBand(2) # Get the IR band\n",
        "\n",
        "xsize = in_band_lv.XSize #número de colunas\n",
        "ysize = in_band_lv.YSize #número de linhas\n",
        "\n",
        "img_de_saida = []\n",
        "for z in range(1, ysize+1):\n",
        "  img_de_saida.append('n{}.tif'.format(z))\n",
        "\n",
        "mw = 49 #moving window\n",
        "lp = mw - 1 #linhas perdidas\n",
        "ns = mw * mw #número de slices\n",
        "lsp = int(lp / 2) #linhas superiores perdidas --------------------------------------------ALTERAR LINHAS 184 E 190\n",
        "sc = ns // 2 #slice central\n",
        "n = 6 #número de linhas a serem resolvidas (ANTERIORMENTE FOI UTILIZADO 6!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "for i in range(0, ysize, n): #início do loop p/ resolver usando chunks\n",
        "    if n + lp + i < ysize: #o n° de linhas a ser lido (n + 48) + o nº de linhas lido anteriormente deve ser menor que o nº total de linhas\n",
        "        rows = n + lp #p/ uam moving window de 49x49, perde-se 48 linhas, logo, p/ resolver 2 linhas, deve-se ler 50\n",
        "    else:\n",
        "        rows = ysize - i #se não restarem 50 linhas para serem lidas, significa que i=1180, logo restam apenas 49 linhas, que serão usadas para resolver a última linha\n",
        "        if rows < mw: #se o número de linhas a ser lido for menor que a moving window (49) o script deve parar\n",
        "            break\n",
        "\n",
        "    in_data_lv = in_band_lv.ReadAsArray(0, i, xsize, rows).astype(np.float32) #lendo a partir da 1ª coluna e da i-linha todas as col e rows-linhas\n",
        "    in_data_mv = in_band_mv.ReadAsArray(0, i, xsize, rows).astype(np.float32)\n",
        "    in_data_lv_k2 = in_band_lv_k2.ReadAsArray(0, i, xsize, rows).astype(np.float32)\n",
        "    in_data_mv_k2 = in_band_mv_k2.ReadAsArray(0, i, xsize, rows).astype(np.float32)\n",
        "    in_data_mv_ko = in_band_mv_ko.ReadAsArray(0, i, xsize, rows).astype(np.float32)\n",
        "\n",
        "    in_data_liv = in_band_liv.ReadAsArray(0, i, xsize, rows).astype(np.float32)\n",
        "    in_data_miv = in_band_miv.ReadAsArray(0, i, xsize, rows).astype(np.float32)\n",
        "    in_data_liv_k2 = in_band_liv_k2.ReadAsArray(0, i, xsize, rows).astype(np.float32)\n",
        "    in_data_miv_k2 = in_band_miv_k2.ReadAsArray(0, i, xsize, rows).astype(np.float32)\n",
        "    in_data_miv_ko = in_band_miv_ko.ReadAsArray(0, i, xsize, rows).astype(np.float32)\n",
        "\n",
        "    driver = gdal.GetDriverByName('GTiff') #\"pegando\" a extensão .tiff (usar 'HFA' para .img) para designá-la na imagem de saída    \n",
        "\n",
        "    for nome in img_de_saida:\n",
        "        out_ds_lv = driver.Create(nome, xsize, n, ns, gdal.GDT_Float32) #criando a imagem de saída, com todas as colunas, 2 linhas, 2401 camadas e no formato float32\n",
        "        out_ds_lv.SetProjection(in_ds.GetProjection()) #atribuindo a mesma projeção da imagem de entrada, EPSG 32724\n",
        "\n",
        "        in_gt = in_ds.GetGeoTransform() #pegando o GeoTransform (origem das coordenadas e tamanho do pixel) da imagem de entrada\n",
        "        subset_ulx, subset_uly = gdal.ApplyGeoTransform(in_gt, 0, i+lsp) #atribuindo a duas variáveis o canto sup esq em que se encontra a linha central da moving window, p/ i=0 a linha central tem canto com x=0 e y=24\n",
        "        out_gt = list(in_gt) #como o GetGeoTransform retorna uma tupla, cria-se uma lista com os mesmos parâmetros\n",
        "        out_gt[0] = subset_ulx #substituindo o parâmetro da coluna\n",
        "        out_gt[3] = subset_uly #substituindo o parâmetro da linha\n",
        "        out_ds_lv.SetGeoTransform(out_gt) #aplicando o novo GeoTransform para a imagem de saída\n",
        "\n",
        "        slices_lv = make_slices(in_data_lv, (mw, mw)) #criando os 2401 slices para a banda do vermelho do Lansat e do MODIS\n",
        "        slices_mv = make_slices(in_data_mv, (mw, mw))\n",
        "        slices_lv_k2 = make_slices(in_data_lv_k2, (mw, mw))\n",
        "        slices_mv_k2 = make_slices(in_data_mv_k2, (mw, mw))\n",
        "        slices_mv_ko = make_slices(in_data_mv_ko, (mw, mw))\n",
        "\n",
        "        difabsv = [abs(valor - slices_lv[sc]) for valor in slices_lv] #usando list comprehension para subtrair de cada slice o slice central\n",
        "        desvpadv = np.std(np.ma.dstack(slices_lv), 2) #tirando o desvio padrão na dimensão z, ou seja, o desvio de todos os pixels da moving window\n",
        "        menorqdesvv = np.ma.masked_where(difabsv > desvpadv, slices_lv) #mascarando os pixels em que a diferença abs é maior que o desvio padrão\n",
        "\n",
        "        difabsv_k2 = [abs(valor - slices_lv_k2[sc]) for valor in slices_lv_k2]\n",
        "        desvpadv_k2 = np.std(np.ma.dstack(slices_lv_k2), 2)\n",
        "        menorqdesvv_k2 = np.ma.masked_where(difabsv_k2 > desvpadv_k2, slices_lv_k2)\n",
        "\n",
        "        filtro_lv_k1 = np.ma.masked_where(menorqdesvv + menorqdesvv_k2 == -1, menorqdesvv) #nenhuma soma será =-1, logo, o valor de menorqdesvv será preservado, mas apenas para os pixels que são neighbours para ambas as variáveis\n",
        "        filtro_lv_k2 = np.ma.masked_where(menorqdesvv + menorqdesvv_k2 == -1, menorqdesvv_k2)\n",
        "# fim do 3º passo\n",
        "\n",
        "        maxsijk = np.where(abs(slices_lv[sc] - slices_mv[sc]) > abs(slices_lv_k2[sc] - slices_mv_k2[sc]),\n",
        "                        abs(slices_lv[sc] - slices_mv[sc]), abs(slices_lv_k2[sc] - slices_mv_k2[sc])) #criando a matriz que apresenta o Sijk máximo entre t1 e t2\n",
        "\n",
        "        sijk1 = abs(filtro_lv_k1 - slices_mv) #criando o Sijk apenas para os neighbours\n",
        "        sijk1_filt = np.ma.masked_where(sijk1 > maxsijk + 0.01, filtro_lv_k1) #aplicando a inequação para o filtro\n",
        "        sijk2 = abs(filtro_lv_k2 - slices_mv_k2)\n",
        "        sijk2_filt = np.ma.masked_where(sijk2 > maxsijk + 0.01, filtro_lv_k2)\n",
        "\n",
        "        sijk1_final = np.ma.masked_where(sijk1_filt + sijk2_filt == -1, sijk1_filt) #selecionando apenas os pixels que obedecem a inequação em t1 e t2\n",
        "\n",
        "        maxtijk = np.where(abs(slices_mv[sc] - slices_mv_ko[sc]) > abs(slices_mv_k2[sc] - slices_mv_ko[sc]),\n",
        "                        abs(slices_mv[sc] - slices_mv_ko[sc]), abs(slices_mv_k2[sc] - slices_mv_ko[sc])) #repetindo o processo p/ Tijk\n",
        "\n",
        "        filtro_mv_ko = np.ma.masked_where(slices_mv_ko + sijk1_final == -1, slices_mv_ko)\n",
        "\n",
        "        tijk1 = abs(slices_mv - filtro_mv_ko)\n",
        "        tijk1_filt = np.ma.masked_where(tijk1 > maxtijk + 0.01, slices_mv)\n",
        "        tijk2 = abs(slices_mv_k2 - filtro_mv_ko)\n",
        "        tijk2_filt = np.ma.masked_where(tijk2 > maxtijk + 0.01, slices_mv_k2)\n",
        "\n",
        "        tijk1_final = np.ma.masked_where(tijk1_filt + tijk2_filt == -1, tijk1_filt)\n",
        "\n",
        "        neighbours = np.ma.masked_where(tijk1_final + sijk1_final == -1, sijk1_final) #definindo os neighbours segundo o Sijk e o Tijk\n",
        "# fim do 4º passo para o v\n",
        "#repetindo os passoas para o infravermelho do Landsat e MODIS\n",
        "        slices_liv = make_slices(in_data_liv, (mw, mw))\n",
        "        slices_miv = make_slices(in_data_miv, (mw, mw))\n",
        "        slices_liv_k2 = make_slices(in_data_liv_k2, (mw, mw))\n",
        "        slices_miv_k2 = make_slices(in_data_miv_k2, (mw, mw))\n",
        "        slices_miv_ko = make_slices(in_data_miv_ko, (mw, mw))\n",
        "\n",
        "        difabsiv = [abs(valoriv - slices_liv[sc]) for valoriv in slices_liv]\n",
        "        desvpadiv = np.std(np.ma.dstack(slices_liv), 2)\n",
        "        menorqdesviv = np.ma.masked_where(difabsiv > desvpadiv, slices_liv)\n",
        "\n",
        "        difabsiv_k2 = [abs(valoriv - slices_liv_k2[sc]) for valoriv in slices_liv_k2]\n",
        "        desvpadiv_k2 = np.std(np.ma.dstack(slices_liv_k2), 2)\n",
        "        menorqdesviv_k2 = np.ma.masked_where(difabsiv_k2 > desvpadiv_k2, slices_liv_k2)\n",
        "\n",
        "        filtro_liv_k1 = np.ma.masked_where(menorqdesviv + menorqdesviv_k2 == -1, menorqdesviv)\n",
        "        filtro_liv_k2 = np.ma.masked_where(menorqdesviv + menorqdesviv_k2 == -1, menorqdesviv_k2)\n",
        "        # fim do 3º passo para o iv\n",
        "\n",
        "        maxsijkiv = np.where(abs(slices_liv[sc] - slices_miv[sc]) > abs(slices_liv_k2[sc] - slices_miv_k2[sc]),\n",
        "                           abs(slices_liv[sc] - slices_miv[sc]), abs(slices_liv_k2[sc] - slices_miv_k2[sc]))\n",
        "\n",
        "        sijk1iv = abs(filtro_liv_k1 - slices_miv)\n",
        "        sijk1iv_filt = np.ma.masked_where(sijk1iv > maxsijkiv + 0.015, filtro_liv_k1)\n",
        "        sijk2iv = abs(filtro_liv_k2 - slices_miv_k2)\n",
        "        sijk2iv_filt = np.ma.masked_where(sijk2iv > maxsijkiv + 0.015, filtro_liv_k2)\n",
        "\n",
        "        sijk1iv_final = np.ma.masked_where(sijk1iv_filt + sijk2iv_filt == -1, sijk1iv_filt)\n",
        "\n",
        "        maxtijkiv = np.where(abs(slices_miv[sc] - slices_miv_ko[sc]) > abs(slices_miv_k2[sc] - slices_miv_ko[sc]),\n",
        "                           abs(slices_miv[sc] - slices_miv_ko[sc]), abs(slices_miv_k2[sc] - slices_miv_ko[sc]))\n",
        "\n",
        "        filtro_miv_ko = np.ma.masked_where(slices_miv_ko + sijk1iv_final == -1, slices_miv_ko)\n",
        "\n",
        "        tijk1iv = abs(slices_miv - filtro_miv_ko)\n",
        "        tijk1iv_filt = np.ma.masked_where(tijk1iv > maxtijkiv + 0.015, slices_miv)\n",
        "        tijk2iv = abs(slices_miv_k2 - filtro_miv_ko)\n",
        "        tijk2iv_filt = np.ma.masked_where(tijk2iv > maxtijkiv + 0.015, slices_miv_k2)\n",
        "\n",
        "        tijk1iv_final = np.ma.masked_where(tijk1iv_filt + tijk2iv_filt == -1, tijk1iv_filt)\n",
        "\n",
        "        neighboursiv = np.ma.masked_where(tijk1iv_final + sijk1iv_final == -1, sijk1iv_final)\n",
        "# fim do 4º passo para o iv\n",
        "\n",
        "        neighbours = np.ma.masked_where(neighbours + neighboursiv == -1, neighbours) #definindo os neighbours segundo o V e o IV\n",
        "        neighbours = neighbours.filled(-99)\n",
        "\n",
        "        out_data_lv = np.ones(in_data_lv.shape, np.float32) * -99 #criando uma matriz no formato da matriz lida (chunk)\n",
        "        for s in range(0, ns): #criando um loop entre as camadas do neighbours\n",
        "            out_data_lv[lsp:-lsp, lsp:-lsp] = neighbours[s] #pegando a 1ª matriz da lista neighbours e inserindo na matriz recém criada\n",
        "            y = (s + 1) // (mw + 1) #calculando a coordenada-y de cada pixel da camada-s atual\n",
        "            x = s + 1 - (y * mw) - 1 #calculando a coordenada-x de cada pixel da camada-s atual\n",
        "            D = 1 + ((np.sqrt(np.square(x - lsp) + np.square(y - lsp))) * 30) / 250 #calculando D de cada pixel da camada-s atual\n",
        "            d_filt = np.where(out_data_lv > 0, D, -99) #atribuindo valor \"D\" para os neighbours\n",
        "\n",
        "            out_data_lv_rec = np.delete(d_filt, np.s_[:lsp], 0) #excluindo as 24 primeiras linhas (de 0 a 23)\n",
        "            out_filtrolv = out_ds_lv.GetRasterBand(s + 1) #pegando a camada da imagem de saída\n",
        "            out_filtrolv.SetNoDataValue(-99)\n",
        "\n",
        "            out_filtrolv.WriteArray(out_data_lv_rec[0:n], 0, 0) #colando as 2 primeiras linhas no início da imagem de saída\n",
        "\n",
        "        out_filtrolv.FlushCache()\n",
        "        out_filtrolv.ComputeStatistics(False)\n",
        "\n",
        "        print('imagem {} criada'.format(nome))\n",
        "\n",
        "        del in_data_lv, in_data_mv, in_data_lv_k2, in_data_mv_k2, in_data_mv_ko, out_ds_lv, slices_lv, slices_mv, slices_lv_k2, slices_mv_k2,\n",
        "         slices_mv_ko, difabsv, desvpadv, menorqdesvv, difabsv_k2, desvpadv_k2, menorqdesvv_k2, filtro_lv_k1, filtro_lv_k2, maxsijk, sijk1,\n",
        "          sijk1_filt, sijk2, sijk2_filt, sijk1_final, maxtijk, filtro_mv_ko, tijk1, tijk1_filt, tijk2, tijk2_filt, tijk1_final, neighbours,\n",
        "           out_data_lv, out_filtrolv, slices_liv, slices_miv, slices_liv_k2, slices_miv_k2, slices_miv_ko, difabsiv, desvpadiv, menorqdesviv,\n",
        "            difabsiv_k2, desvpadiv_k2, menorqdesviv_k2, filtro_liv_k1, filtro_liv_k2, maxsijkiv, sijk1iv, sijk1iv_filt, sijk2iv, sijk2iv_filt,\n",
        "             sijk1iv_final, maxtijkiv, filtro_miv_ko, tijk1iv, tijk1iv_filt, tijk2iv, tijk2iv_filt, tijk1iv_final, neighboursiv, in_data_liv,\n",
        "              in_data_miv, in_data_liv_k2, in_data_miv_k2, in_data_miv_ko, out_data_lv_rec\n",
        "\n",
        "        break\n",
        "\n",
        "    q = len(img_de_saida)\n",
        "    if q == 0:\n",
        "        break\n",
        "    else:\n",
        "        img_de_saida.pop(0)\n",
        "\n",
        "del in_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5beygKep1hW"
      },
      "source": [
        "# STARFM PART II"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-FewXMVF6Yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b925bc-950d-4fb1-f4f9-145c16954230"
      },
      "source": [
        "os.chdir(r\"/content/drive/MyDrive/colab_imagens\")\n",
        "\n",
        "imagem_lv = 'reflectance_2016_10_29.tif' # Load the first (Albedo, surface reflectance or Ts) LANDSAT image (the day before the predicted date)\n",
        "in_ds = gdal.Open(imagem_lv)\n",
        "in_band_lv = in_ds.GetRasterBand(4)\n",
        "\n",
        "imagem_mv = 'modis_gq2016_10_29.tif' # Load the first (Albedo, surface reflectance or Ts) MODIS image (the day before the predicted date)\n",
        "in_ds_mv = gdal.Open(imagem_mv)\n",
        "in_band_mv = in_ds_mv.GetRasterBand(2)\n",
        "\n",
        "imagem_lv_k2 = 'reflectance_2017_01_17.tif' # Load the second (Albedo, surface reflectance or Ts) LANDSAT image (the day after the predicted date)\n",
        "in_ds_k2 = gdal.Open(imagem_lv_k2)\n",
        "in_band_lv_k2 = in_ds_k2.GetRasterBand(4)\n",
        "\n",
        "imagem_mv_k2 = 'modis_gq2017_01_17.tif' # Load the second (Albedo, surface reflectance or Ts) MODIS image (the day after the predicted date)\n",
        "in_ds_mv_k2 = gdal.Open(imagem_mv_k2)\n",
        "in_band_mv_k2 = in_ds_mv_k2.GetRasterBand(2)\n",
        "\n",
        "imagem_mv_ko = 'modis_gq2016_12_31.tif' # Load the third (Albedo, surface reflectance or Ts) MODIS image (predicted date)\n",
        "in_ds_mv_ko = gdal.Open(imagem_mv_ko)\n",
        "in_band_mv_ko = in_ds_mv_ko.GetRasterBand(2)\n",
        "\n",
        "xsize = in_band_lv.XSize #número de colunas\n",
        "ysize = in_band_lv.YSize #número de linhas\n",
        "\n",
        "print(ysize)\n",
        "\n",
        "neighbours = []\n",
        "for z in range(1, ysize+1):\n",
        "  neighbours.append('n{}.tif'.format(z))\n",
        "\n",
        "mw = 49 #moving window\n",
        "lp = mw - 1 #linhas perdidas\n",
        "ns = mw * mw #número de slices\n",
        "lsp = int(lp / 2) #linhas superiores perdidas --------------------------------------------ALTERAR LINHAS 77-80, 98 e 100\n",
        "sc = ns // 2 #slice central\n",
        "n = 6 #número de linhas a serem resolvidas\n",
        "\n",
        "for i in range(0, ysize, n):\n",
        "    if n + lp + i < ysize:\n",
        "        rows = n + lp\n",
        "    else:\n",
        "        rows = ysize - i\n",
        "        if rows < mw:\n",
        "            break\n",
        "\n",
        "    in_data_lv = in_band_lv.ReadAsArray(0, i, xsize, rows).astype(np.float32)\n",
        "    in_data_mv = in_band_mv.ReadAsArray(0, i, xsize, rows).astype(np.float32)\n",
        "    in_data_lv_k2 = in_band_lv_k2.ReadAsArray(0, i, xsize, rows).astype(np.float32)\n",
        "    in_data_mv_k2 = in_band_mv_k2.ReadAsArray(0, i, xsize, rows).astype(np.float32)\n",
        "    in_data_mv_ko = in_band_mv_ko.ReadAsArray(0, i, xsize, rows).astype(np.float32)\n",
        "\n",
        "    slices_lv = make_slices(in_data_lv, (mw, mw))\n",
        "    slices_mv = make_slices(in_data_mv, (mw, mw))\n",
        "    slices_lv_k2 = make_slices(in_data_lv_k2, (mw, mw))\n",
        "    slices_mv_k2 = make_slices(in_data_mv_k2, (mw, mw))\n",
        "    slices_mv_ko = make_slices(in_data_mv_ko, (mw, mw))\n",
        "\n",
        "    sijk1 = abs(np.ma.dstack(slices_lv) - np.ma.dstack(slices_mv)) #calculando Sijk para T1\n",
        "    sijk2 = abs(np.ma.dstack(slices_lv_k2) - np.ma.dstack(slices_mv_k2)) #calculando Sijk para T2\n",
        "\n",
        "    tijk1 = abs(np.ma.dstack(slices_mv) - np.ma.dstack(slices_mv_ko)) #calculando Tijk para T1\n",
        "    tijk2 = abs(np.ma.dstack(slices_mv_k2) - np.ma.dstack(slices_mv_ko)) #calculando Tijk para T2\n",
        "    ysize_teste = sijk1.shape\n",
        "    print('Esse é o número de linhas de Sijk1 {}'.format(ysize_teste))\n",
        "    for nome in neighbours:\n",
        "        in_ds_nome = gdal.Open(nome) #lendo as imagens que possuem as informações de \"D\" nos pixels que são neighbours\n",
        "        lendo = in_ds_nome.ReadAsArray().astype(np.float32) #ao inves de ler uma banda da img de entrada, lê-se todas\n",
        "        lendo = np.ma.masked_where(lendo == -99, lendo) #mascarando os valores dos pixels que não são neighbours\n",
        "\n",
        "        s1 = np.ones(lendo.shape, np.float32) * -99 #criando uma matriz no formato da imagem lida\n",
        "        s2 = np.ones(lendo.shape, np.float32) * -99\n",
        "        t1 = np.ones(lendo.shape, np.float32) * -99\n",
        "        t2 = np.ones(lendo.shape, np.float32) * -99\n",
        "\n",
        "        for c in range(0, ns): #criando um loop entre o nº de matrizes das listas Sijk e Tijk\n",
        "          if n + lp + i < ysize:\n",
        "            s1[c, :, lsp:-lsp] = sijk1[:, :, c] #pegando o sijk1 (lista empilhada(y, x, z)) e colocando na matriz (z, y, x)\n",
        "            s2[c, :, lsp:-lsp] = sijk2[:, :, c]\n",
        "            t1[c, :, lsp:-lsp] = tijk1[:, :, c]\n",
        "            t2[c, :, lsp:-lsp] = tijk2[:, :, c]\n",
        "          else:\n",
        "            lin = int(ysize - i - lp)\n",
        "            s1[c, :lin, lsp:-lsp] = sijk1[:, :, c] #pegando o sijk1 (lista empilhada(y, x, z)) e colocando na matriz (z, y, x)\n",
        "            s2[c, :lin, lsp:-lsp] = sijk2[:, :, c]\n",
        "            t1[c, :lin, lsp:-lsp] = tijk1[:, :, c]\n",
        "            t2[c, :lin, lsp:-lsp] = tijk2[:, :, c]\n",
        "\n",
        "        Cijk1 = lendo * np.log((s1 * 10000) + 1) * np.log((t1 * 10000) + 1)\n",
        "        Cijk2 = lendo * np.log((s2 * 10000) + 1) * np.log((t2 * 10000) + 1)\n",
        "        divisao1 = 1 / Cijk1\n",
        "        divisao2 = 1 / Cijk2\n",
        "\n",
        "\n",
        "        Wijk1 = divisao1 / (divisao1.sum(0) + divisao2.sum(0)) #na função .sum(0) a soma é na vertical (a matriz numpy tem formato z, y, x)\n",
        "        Wijk2 = divisao2 / (divisao1.sum(0) + divisao2.sum(0)) #(z, y, x) -> (0, 1, 2), por isso usa-se .sum(0)\n",
        "\n",
        "        Wijk1 = Wijk1.filled(0) #para que os pixels que não são neighbours não participem do cálculo de \"L\", substiu-se os mesmos por 0\n",
        "        Wijk2 = Wijk2.filled(0)\n",
        "\n",
        "        M_L_M_1= slices_mv_ko[sc] + slices_lv[sc] - slices_mv[sc]      #M(xw/2, yw/2, to) + L(xw/2, yw/2, tk1) - M(xw/2, yw/2, tk1)\n",
        "        M_L_M_2 = slices_mv_ko[sc] + slices_lv_k2[sc] - slices_mv_k2[sc]#M(xw/2, yw/2, to) + L(xw/2, yw/2, tk2) - M(xw/2, yw/2, tk2)\n",
        "        \n",
        "        temporal_k0_igual = np.ones((n, xsize), np.float) * -99\n",
        "        spectral_k0_igual = np.ones((n, xsize), np.float) * -99\n",
        "        temporal_k2_igual = np.ones((n, xsize), np.float) * -99\n",
        "        spectral_k2_igual = np.ones((n, xsize), np.float) * -99\n",
        "        \n",
        "        if n + lp + i < ysize:\n",
        "          temporal_k0_igual[:, lsp:-lsp] = slices_mv_ko[sc] - slices_mv[sc]\n",
        "          spectral_k0_igual[:, lsp:-lsp] = slices_lv[sc] - slices_mv[sc]\n",
        "          temporal_k2_igual[:, lsp:-lsp] = slices_mv_ko[sc] - slices_mv_k2[sc]\n",
        "          spectral_k2_igual[:, lsp:-lsp] = slices_lv_k2[sc] - slices_mv_k2[sc]\n",
        "        else:\n",
        "          temporal_k0_igual[:2, lsp:-lsp] = slices_mv_ko[sc] - slices_mv[sc]\n",
        "          spectral_k0_igual[:2, lsp:-lsp] = slices_lv[sc] - slices_mv[sc]\n",
        "          temporal_k2_igual[:2, lsp:-lsp] = slices_mv_ko[sc] - slices_mv_k2[sc]\n",
        "          spectral_k2_igual[:2, lsp:-lsp] = slices_lv_k2[sc] - slices_mv_k2[sc]\n",
        "\n",
        "        if n + lp + i < ysize:\n",
        "          T1 = np.ones((n, xsize), np.float) * -99\n",
        "          T2 = np.ones((n, xsize), np.float) * -99\n",
        "          T1[:, lsp:-lsp] = M_L_M_1[:, :]             #pegando o M_L_M_1 e colocando na matriz do numpy\n",
        "          T2[:, lsp:-lsp] = M_L_M_2[:, :]             #pegando o M_L_M_2 e colocando na matriz do numpy       \n",
        "        else:\n",
        "          T1 = np.ones((6, xsize), np.float) * -99\n",
        "          T2 = np.ones((6, xsize), np.float) * -99  \n",
        "          T1[:2, lsp:-lsp] = M_L_M_1[:, :]             #pegando o M_L_M_1 e colocando na matriz do numpy\n",
        "          T2[:2, lsp:-lsp] = M_L_M_2[:, :]             #pegando o M_L_M_2 e colocando na matriz do numpy\n",
        "        \n",
        "        if n + lp + i < ysize:\n",
        "          L = np.zeros((n, xsize), np.float) #criando uma matriz com valores 0, 2 linhas e xsize colunas\n",
        "        else:\n",
        "          L = np.zeros((6, xsize), np.float) \n",
        "        for m in range(0, ns): #criando um loop dentro do nº de camadas do Wijk\n",
        "            L = L + ((Wijk1[m] * T1) + (Wijk2[m] * T2)) #L inicialmente é 0, mas vai sendo substituído ao passo em que as somas vão se realizando\n",
        "\n",
        "        L = np.where(temporal_k0_igual == 0.0, T1, L)# Filtro p/ quando não há diferença entre imgs MODIS (01 e 00)\n",
        "        L = np.where(spectral_k0_igual == 0.0, T1, L)# Filtro p/ quando não há diferença entre imgs L-M (01)\n",
        "        L = np.where(temporal_k2_igual == 0.0, T2, L)# Filtro p/ quando não há diferença entre imgs MODIS (02 e 00)\n",
        "        L = np.where(spectral_k2_igual == 0.0, T2, L)# Filtro p/ quando não há diferença entre imgs L-M (02)\n",
        "\n",
        "        driver = gdal.GetDriverByName('GTiff')\n",
        "        out_ds = driver.Create('L{}.tif'.format(i), xsize, n, 1, gdal.GDT_Float32) #criando a imagem de saída com xsize colunas, 2 linhas e 1 camada\n",
        "        out_ds.SetProjection(in_ds_nome.GetProjection())\n",
        "        out_ds.SetGeoTransform(in_ds_nome.GetGeoTransform())\n",
        "        out = out_ds.GetRasterBand(1)\n",
        "        out.SetNoDataValue(-99)\n",
        "\n",
        "        out.WriteArray(L[0:n], 0, 0) #escrevendo as duas primeiras (e únicas) linhas de L no início da imagem de saída\n",
        "\n",
        "        out.FlushCache()\n",
        "        out.ComputeStatistics(False)\n",
        "\n",
        "        print('imagem L{}.tif criada'.format(i))\n",
        "\n",
        "        del in_data_lv\n",
        "        del in_data_mv\n",
        "        del in_data_lv_k2\n",
        "        del in_data_mv_k2\n",
        "        del in_data_mv_ko\n",
        "        del slices_lv\n",
        "        del slices_mv\n",
        "        del slices_lv_k2\n",
        "        del slices_mv_k2\n",
        "        del slices_mv_ko\n",
        "        del in_ds_nome\n",
        "        del lendo\n",
        "        del s1\n",
        "        del s2\n",
        "        del t1\n",
        "        del t2\n",
        "        del Cijk1\n",
        "        del Cijk2\n",
        "        del Wijk1\n",
        "        del Wijk2\n",
        "        del M_L_M_1\n",
        "        del M_L_M_2\n",
        "        del T1\n",
        "        del T2\n",
        "        del out\n",
        "        del out_ds\n",
        "\n",
        "        break\n",
        "\n",
        "    q = len(neighbours)\n",
        "    if q == 0:\n",
        "        break\n",
        "    else:\n",
        "        neighbours.pop(0)\n",
        "\n",
        "del in_ds\n",
        "del in_ds_mv\n",
        "del in_ds_k2\n",
        "del in_ds_mv_k2\n",
        "del in_ds_mv_ko"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "182\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:89: RuntimeWarning: invalid value encountered in log\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:90: RuntimeWarning: invalid value encountered in log\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imagem L0.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L6.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L12.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L18.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L24.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L30.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L36.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L42.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L48.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L54.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L60.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L66.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L72.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L78.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L84.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L90.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L96.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L102.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L108.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L114.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L120.tif criada\n",
            "Esse é o número de linhas de Sijk1 (6, 181, 2401)\n",
            "imagem L126.tif criada\n",
            "Esse é o número de linhas de Sijk1 (2, 181, 2401)\n",
            "imagem L132.tif criada\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMq1UJOop6Ox"
      },
      "source": [
        "# Merging raster data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hFlx0RI2znR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b904c538-6989-48c1-feb8-cbb265f84bc4"
      },
      "source": [
        "# Merge raster data produced after the STARFM execution\n",
        "\n",
        "# What is the name of the output image?\n",
        "var = 'ref_iv_' #examples: albedo, ref_iv, ref_verm and tsup\n",
        "date = '2016_12_31' #y-m-d\n",
        "name = var + date\n",
        "\n",
        "import glob\n",
        "\n",
        "# list all files in directory that match pattern\n",
        "List = glob.glob(\"L*.tif\")\n",
        "print(List)\n",
        "\n",
        "# build virtual raster and convert to geotiff 'n{}.tif'.format(z)\n",
        "vrt = gdal.BuildVRT(\"merged.vrt\", List)\n",
        "gdal.Translate(\"{}.tif\".format(name), vrt, xRes = 30, yRes = -30)\n",
        "vrt = None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['L0.tif', 'L6.tif', 'L12.tif', 'L18.tif', 'L24.tif', 'L30.tif', 'L36.tif', 'L42.tif', 'L48.tif', 'L54.tif', 'L60.tif', 'L66.tif', 'L72.tif', 'L78.tif', 'L84.tif', 'L90.tif', 'L96.tif', 'L102.tif', 'L108.tif', 'L114.tif', 'L120.tif', 'L126.tif', 'L132.tif']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T37dITPyp-_8"
      },
      "source": [
        "# Exporting land use and land cover image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wtubb9Jpa8cS"
      },
      "source": [
        "data1 = ee.String('2016')\n",
        "imagem_1 = ee.String('mapbiomas_')\n",
        "saida_1 = imagem_1.cat(data1)\n",
        "\n",
        "#area = ee.Geometry.Polygon(\n",
        "#        [[[-40.43748032601223, -9.375816954123401],\n",
        "#          [-40.43748032601223, -9.411721142856367],\n",
        "#          [-40.38821351082668, -9.411721142856367],\n",
        "#          [-40.38821351082668, -9.375816954123401]]])\n",
        "area = ee.Geometry.Polygon(\n",
        "        [[[-40.443765656859135, -9.369681936878271],\n",
        "          [-40.443765656859135, -9.4184573955032],\n",
        "          [-40.38179589977906, -9.4184573955032],\n",
        "          [-40.38179589977906, -9.369681936878271]]]);\n",
        "\n",
        "#img = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').filterDate('2015-08-24', '2015-08-25')\n",
        "\n",
        "mapbiomas = ee.Image('projects/mapbiomas-workspace/public/collection5/mapbiomas_collection50_integration_v1').select(['classification_2016'])\n",
        "\n",
        "task1 = ee.batch.Export.image.toDrive(image=mapbiomas, folder='colab_imagens', description='Mapbiomas', scale=30, region=area, fileNamePrefix=saida_1.getInfo(), crs='EPSG:32724', fileFormat='GeoTIFF')\n",
        "task1.start()\n",
        "task1.status()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0ODIMR0obK0"
      },
      "source": [
        "# SEBAL SCRIPT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfdwdzHaEEHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4138fb28-3fb8-4771-fad3-373923d280a8"
      },
      "source": [
        "area = ee.Geometry.Polygon(\n",
        "        [[[-40.43748032601223, -9.375816954123401],\n",
        "          [-40.43748032601223, -9.411721142856367],\n",
        "          [-40.38821351082668, -9.411721142856367],\n",
        "          [-40.38821351082668, -9.375816954123401]]])\n",
        " \n",
        "os.chdir(r\"/content/drive/MyDrive/colab_imagens\")\n",
        "# Albedo is the image used to GetProjection(), GetGeoTransform(), XSize and YSize\n",
        "albedo_open = gdal.Open('albedo_2016_12_31.tif')\n",
        "albedo_in_band = albedo_open.GetRasterBand(1)\n",
        "albedo_in_data = albedo_in_band.ReadAsArray().astype(np.float)\n",
        " \n",
        "NIR_open = gdal.Open('ref_iv_2016_12_31.tif')#.GetRasterBand(1).ReadAsArray().astype(np.float)# Near Infra-red Image\n",
        "NIR_in_band = NIR_open.GetRasterBand(1)\n",
        "NIR_in_data = NIR_in_band.ReadAsArray().astype(np.float)\n",
        " \n",
        "RED_open = gdal.Open('ref_verm_2016_12_31.tif')#.GetRasterBand(1).ReadAsArray().astype(np.float)# Red image\n",
        "RED_in_band = RED_open.GetRasterBand(1)\n",
        "RED_in_data = RED_in_band.ReadAsArray().astype(np.float)\n",
        " \n",
        "tsup_open = gdal.Open('tsup_2016_12_31.tif')#.GetRasterBand(1).ReadAsArray().astype(np.float)# Surface Temperature Image\n",
        "tsup_in_band = tsup_open.GetRasterBand(1)\n",
        "tsup_in_data = tsup_in_band.ReadAsArray().astype(np.float)\n",
        " \n",
        "mapbiomas_open = gdal.Open('mapbiomas_2016.tif')#.GetRasterBand(1).ReadAsArray().astype(np.int)# Land use and land cover Image\n",
        "mapbiomas_in_band = mapbiomas_open.GetRasterBand(1)\n",
        "mapbiomas = mapbiomas_in_band.ReadAsArray().astype(np.float)\n",
        "mapbiomas_in_data = np.ones(albedo_in_data.shape, np.float32) * -99\n",
        "#lsp = int(lp / 2) #linhas/colunas perdidas durante a execução do STARFM (24)\n",
        "mapbiomas_in_data[:-4, 24:-24] = mapbiomas[24:-24, 24:-24]\n",
        " \n",
        "albedo = np.ma.masked_where(albedo_in_data < 0, albedo_in_data)\n",
        "albedo = np.ma.masked_where(albedo > 1, albedo)\n",
        " \n",
        "NIR = np.where(NIR_in_data < 0.0, 0.0, NIR_in_data)\n",
        "NIR = np.ma.masked_where(NIR < 0, NIR)\n",
        " \n",
        "RED = np.where(RED_in_data < 0.0, 0.0, RED_in_data)\n",
        "RED = np.ma.masked_where(RED < 0, RED)\n",
        " \n",
        "tsup = np.ma.masked_where(tsup_in_data < 273, tsup_in_data)\n",
        "tsup = np.ma.masked_where(tsup > 340, tsup)\n",
        " \n",
        "lat = -9.357#///////// Inserir a Latitude média do RECORTE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        " \n",
        "ta = 34.7#/////////// Inserir A Ta (°C) no instante da passagem do satélite!!!!!!!!!!!!!!!!!!!!\n",
        "ur = 29.62#/////////// Inserir A UR (%) no instante da passagem do satélite!!!!!!!!!!!!!!!!!!!!!\n",
        "pa = 96.802#/////////// Inserir A Pa (kPa) no instante da passagem do satélite!!!!!!!!!!!!!!!!!!!\n",
        " \n",
        "u = 3.062#//////////// Inserir a Vel do vento (m/s, a 10m) no instante da passagem do satélite!!\n",
        "rs_24 = 26.3#//////// Inserir A Radiação global diária (MJ)!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        " \n",
        "precipitation60 = 45.2# //Inserir a precipitação dos últimos 60 dias!!!!!!!!!!!!\n",
        "ETr60 = 381.9#///////////Inserir a ETref dos últimos 60 dias!!!!!!!!!!!!!!!!!!!\n",
        " \n",
        "ETref_00 = 4.944755653\n",
        "ETref_periodo_00 = 12.14\n",
        " \n",
        "DOA = 366#//////////// Inserir o Dia de Ordem do Ano!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "data = '2016_12_31_'#// Inserir A DATA (ANO-MÊS-DIA)!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        " \n",
        "ang_zen = ee.Image('MODIS/006/MYD09GA/2016_12_31')# // Inserir A DATA (ANO-MÊS-DIA)!!!!!!!!!!!!!!!!\n",
        " \n",
        "#EXPORTS#####################################################\n",
        "nome_ndvi = 'ndvi.tif'\n",
        "export_ndvi = data + nome_ndvi\n",
        " \n",
        "nome_et24 = 'et_24.tif'\n",
        "export_et24 = data + nome_et24\n",
        " \n",
        "#CALCULUS####################################################\n",
        "Tfac = 2.6 - (13*(precipitation60/ETr60))\n",
        "print(Tfac)\n",
        " \n",
        "#//calculando o dr e Cos(z)\n",
        "argumento = 2*np.pi*(DOA-1)/365\n",
        "dr = 1.000110+0.034221*np.cos(argumento)+0.001280*np.sin(argumento)+0.000719*np.cos(2*argumento)+0.000077*np.sin(2*argumento)\n",
        "print ('dr é: ', dr)\n",
        " \n",
        "cos_z_img = ang_zen.select(['SolarZenith']).multiply(0.01).multiply(np.pi).divide(180).cos()\n",
        " \n",
        "cos_z_red = cos_z_img.reduceRegion(\n",
        "  ee.Reducer.mean(),\n",
        "  area,\n",
        "  30)\n",
        " \n",
        "#print(cos_z_red)\n",
        " \n",
        "cos_z = cos_z_red.getInfo()['SolarZenith']\n",
        " \n",
        "elevacao = ((np.pi/2) - math.acos(cos_z))*180/np.pi\n",
        " \n",
        "print ('Cos(z) é: ', cos_z)\n",
        "print ('elevacao é: ', elevacao)\n",
        " \n",
        "#//calculando o SAVI\n",
        "savi = (1.1 * (NIR - RED)) / (0.1 + NIR + RED)\n",
        "#print ('O SAVI é: ', savi)\n",
        " \n",
        "#//calculando o IAF\n",
        "iaf = np.where(savi < 0.688000, np.log((0.69 - savi) / 0.59) * (-1) / 0.91, 6)\n",
        "iafcorrigido = np.where(savi < 0.000001, 0, iaf)\n",
        " \n",
        "#// calculando e_o\n",
        "e_o = np.where(iafcorrigido > 2.999999, 0.98, 0.95 + (0.01 * iafcorrigido))\n",
        "e_ocorrigido = np.where(iafcorrigido < 0.000001, 0.985, e_o)\n",
        " \n",
        "#// calculando e_nb\n",
        "e_nb = np.where(iafcorrigido > 2.999999, 0.98, 0.97 + (0.0033 * iafcorrigido))\n",
        "e_nbcorrigido = np.where(iafcorrigido < 0.000001, 0.99, e_nb)\n",
        " \n",
        "#// calculando Rol,emi\n",
        "rol_emi = e_o * 0.0000000567 * tsup**4\n",
        " \n",
        "#// calculando a transmitância\n",
        "e_a = 0.61078 * (np.exp((17.269 * ta)/(237.3 + ta))) * ur/100\n",
        "w = (10 * (0.14 * 10 * e_a * (pa/101))) + 0.21\n",
        "transmitancia = 0.35 + 0.627 * (np.exp((0.00146*(-1)*pa/cos_z) - 0.075 * ((w/cos_z)**0.4)))\n",
        " \n",
        "print ('e_a equivale a : ', e_a)\n",
        "print ('w equivale a : ', w)\n",
        "print ('transmitancia equivale a : ', transmitancia)\n",
        " \n",
        "#//calculando a Radiação global (Allen et al., 2007)\n",
        "roc = 1367 * dr * cos_z * transmitancia\n",
        "print ('a radiação global é: ', roc)\n",
        " \n",
        "#// calculando emissividade atm\n",
        "e_atm = 0.625 * (((1000 * e_a) / (273.15 + ta)) ** 0.131)\n",
        " \n",
        "#// calculando Rol,atm\n",
        "rol_atm = e_atm * 0.0000000567 * (ta + 273.15)**4\n",
        "print ('a radiação atm é: ', rol_atm)\n",
        " \n",
        "#// calculando Rn\n",
        "rn = (1 - albedo) * roc - rol_emi + e_ocorrigido * rol_atm \n",
        " \n",
        "#// calculando NDVI e G\n",
        "ndvi = (NIR - RED) / (NIR + RED)\n",
        " \n",
        "#print ('o NDVI é: ', ndvi)\n",
        " \n",
        "g_corrigido = np.where(ndvi < 0.05, 0.3 * rn, ((tsup - 273.15) * (0.0038 + 0.0074 * albedo) * (1 - 0.98 * (ndvi ** 4))) * rn)\n",
        " \n",
        "#//#//#//#//#//#//#//#//#//#// BALANÇO DE ENERGIA#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#///\n",
        "#//PIXEL FRIO CIMEC\n",
        " \n",
        "p95 = np.percentile(ndvi[ndvi > 0], 95)\n",
        "print('Esse é o percentil 95 do NDVI ', p95)\n",
        " \n",
        "f1_frio_0 = np.ma.masked_where(mapbiomas_in_data != 36, ndvi)\n",
        "f1_frio = np.ma.masked_where(f1_frio_0 < p95, tsup)\n",
        " \n",
        "p20 =  np.percentile(f1_frio[f1_frio > 0], 20)\n",
        "print('esse é o percentil 20 da Tsup: ', p20)\n",
        " \n",
        "f2_frio = np.ma.masked_where(f1_frio > p20, f1_frio)\n",
        " \n",
        "f2_frio_med = np.mean(f2_frio[f2_frio > 0])\n",
        " \n",
        "f3_frio = np.ma.masked_where((f2_frio_med + 0.2) < f2_frio, f2_frio)\n",
        "f3_frio = np.ma.masked_where(f2_frio < (f2_frio_med - 0.2), f3_frio)\n",
        " \n",
        "albedo_chave = 0.001343 * elevacao + (0.3281 * np.exp((-0.0188) * elevacao))\n",
        "print('albedo chave é: ', albedo_chave)\n",
        " \n",
        "f4_frio = np.ma.masked_where((albedo_chave + 0.02) < albedo, f3_frio)\n",
        "f4_frio = np.ma.masked_where(albedo < (albedo_chave - 0.02), f4_frio)\n",
        " \n",
        "p_frio_ok = f4_frio.min()\n",
        " \n",
        "print('Esse é o pixel frio do CIMEC: ', p_frio_ok)\n",
        " \n",
        "#//PIXEL QUENTE CIMEC\n",
        "p5 = np.percentile(ndvi[ndvi>0], 5)\n",
        " \n",
        "f1_quente = np.ma.masked_where(ndvi > p5, tsup)\n",
        " \n",
        "p80 = np.percentile(f1_quente[f1_quente > 0], 80)\n",
        " \n",
        "f2_quente = np.ma.masked_where(f1_quente < p80, f1_quente)\n",
        " \n",
        "f2_quente_med = np.mean(f2_quente)\n",
        " \n",
        "f2_quente_med_2 = f2_quente_med - Tfac\n",
        " \n",
        "f3_quente = np.ma.masked_where(f2_quente > (f2_quente_med_2 + 3.0), f2_quente)\n",
        "f3_quente = np.ma.masked_where(f3_quente < (f2_quente_med_2 - 3.0), f3_quente)\n",
        "#// ESSE nº de corte do f3_quente pode precisar de ajuste, usar 2.0 ou 3.5 pode resolver...\n",
        " \n",
        "p_quente_ok = f3_quente.max()\n",
        " \n",
        "print('Esse é o pixel quente do CIMEC: ', p_quente_ok)\n",
        " \n",
        "#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#///\n",
        " \n",
        "#//SAVI do pixel quente\n",
        "savi_pq = np.ma.masked_where(ndvi > p5, tsup)\n",
        "savi_pq = np.ma.masked_where(savi_pq != p_quente_ok, savi)\n",
        "savi_quente = savi_pq.max()\n",
        "print ('O savi do Pixel quente é: ', savi_quente)\n",
        " \n",
        "#//Rn do pixel quente\n",
        "rn_pq = np.ma.masked_where(ndvi > p5, tsup)\n",
        "rn_pq = np.ma.masked_where(rn_pq != p_quente_ok, rn)\n",
        "rn_quente = rn_pq.max()\n",
        "print ('O Rn do Pixel quente é: ', rn_quente)\n",
        " \n",
        "#//G do pixel quente\n",
        "g_pq = np.ma.masked_where(ndvi > p5, tsup)\n",
        "g_pq = np.ma.masked_where(g_pq != p_quente_ok, g_corrigido)\n",
        "g_quente = g_pq.max()\n",
        "print ('O G do Pixel quente é: ', g_quente)\n",
        " \n",
        "#//calculando os coeficientes da regressão linear dT = a + bT\n",
        " \n",
        "u_estrela1 = u * 0.41/np.log(10/0.024)\n",
        "u200 = u_estrela1 * np.log(200/0.024)/0.41\n",
        "zom = np.exp(-5.809+5.62*savi_quente)\n",
        "u_estrela = (u200*0.41)/np.log(200/zom)\n",
        "rah = (np.log(2/0.1))/(0.41 * u_estrela)\n",
        "b = (rn_quente - g_quente)*rah / (1.15*1004*(p_quente_ok - p_frio_ok))\n",
        "a = (-1)*b*(p_frio_ok - 273.15)\n",
        "dT = a + b *(p_quente_ok - 273.15)\n",
        "H = 1.15 * 1004 * (a + (b * (p_quente_ok - 273.15)))/rah\n",
        " \n",
        "print ('O Fluxo de calor sensível H é: ', H)\n",
        "rn_g = rn_quente - g_quente\n",
        "print ('Rn - G é: ', rn_g)\n",
        "#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//calculando nas imagens#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//\n",
        "zom_img = np.exp(-5.809+5.62*savi)\n",
        "u_estrela_img = (u200*0.41)/np.log(200/zom_img)\n",
        "rah_img = (np.log(2/0.1))/(0.41 * u_estrela_img)\n",
        "H_img = 1.15 * 1004 * (a + (b * (tsup - 273.15)))/rah_img\n",
        " \n",
        "#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//INICIO DO PROCESSO ITERATIVO#//#//#//#//#//#//#//#//#//#//#//#//#//#//#///\n",
        "#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//1ª CORREÇÃO#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#///\n",
        "L = (-1)*1.15*1004*(u_estrela**3)*p_quente_ok/(0.41*9.81*H)\n",
        " \n",
        "x_0_1m = ((1-16)*0.1/L)**0.25\n",
        "x_2m = ((1-16)*2/L)**0.25\n",
        "x_200m = ((1-16)*200/L)**0.25\n",
        " \n",
        "psi_h0_1 = 2*np.log((1+(x_0_1m**2))/2)\n",
        "psi_h2 = 2*np.log((1+(x_2m**2))/2)\n",
        "psi_m200 = 2*np.log((1+x_200m)/2)+np.log((1+x_200m**2)/2)-2*np.arctan(x_200m)+0.5*np.pi\n",
        " \n",
        "u_estrela_corr_1 = u200*0.41/((np.log(200/zom))-psi_m200)\n",
        "rah_corr_1 = (np.log(2/0.1)-psi_h2+psi_h0_1)/(0.41*u_estrela_corr_1)\n",
        "b_corr = (rn_quente - g_quente)*rah_corr_1 / (1.15*1004*(p_quente_ok - p_frio_ok))\n",
        "a_corr = (-1)*b_corr*(p_frio_ok - 273.15)\n",
        "dT_corr = a_corr + b_corr *(p_quente_ok - 273.15)\n",
        "H = 1.15 * 1004 * (a_corr + (b_corr * (p_quente_ok - 273.15)))/rah_corr_1\n",
        " \n",
        "#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//#//calculando 1ª CORREÇÃO nas imagens #//#//#//#//#//#//#//#//#//#//#//#//#//#//#//\n",
        "L_img = (-1)*1.15*1004*(u_estrela_img**3)*tsup/(0.41*9.81*H_img)\n",
        "x_0_1m_img = ((1-16)*0.1/L_img)**0.25\n",
        "x_2m_img = ((1-16)*2/L_img)**0.25\n",
        "x_200m_img = ((1-16)*200/L_img)**0.25\n",
        " \n",
        "psi_h0_1_img_c = np.where(L_img < 0.0, 2*np.log((1+(x_0_1m_img**2))/2), (-1)*5*(0.1/L_img))\n",
        "psi_h2_img_c = np.where(L_img < 0.0, 2*np.log((1+(x_2m_img**2))/2), (-1)*5*(2/L_img))\n",
        "psi_m200_img_c = np.where(L_img < 0.0, 2*np.log((1+x_200m_img)/2)+np.log((1+(x_200m_img**2))/2)-(2*np.arctan(x_200m_img))+0.5*(np.pi),\n",
        "                          (-1)*5*(200/L_img))\n",
        "u_estrela_corr_img_1 = (u200*0.41)/((np.log(200/zom_img))-psi_m200_img_c)\n",
        "rah_corr_img_1 = (np.log(2/0.1)-psi_h2_img_c+psi_h0_1_img_c)/(0.41 * u_estrela_corr_img_1)\n",
        "H_corr_img = 1.15 * 1004 * (a_corr + (b_corr * (tsup - 273.15)))/rah_corr_img_1\n",
        " \n",
        "err_rel = abs(rah_corr_1 - rah)*100/rah\n",
        "print('a vale: ', a_corr, 'b vale: ', b_corr, 'O Erro relativo é: ', err_rel)\n",
        "print('H é: ', H)\n",
        " \n",
        "lista_u_star = []\n",
        "lista_rah = []\n",
        "lista_u_star_img = []\n",
        "lista_rah_img = []\n",
        " \n",
        "lista_u_star.append(u_estrela_corr_1)\n",
        "lista_rah.append(rah_corr_1)\n",
        "lista_u_star_img.append(u_estrela_corr_img_1)\n",
        "lista_rah_img.append(rah_corr_img_1)\n",
        " \n",
        " \n",
        "rodadas = 1\n",
        " \n",
        "while err_rel > 3:\n",
        "    rodadas += 1\n",
        "    lista_u_star.append('u_estrela_corr_{}'.format(rodadas))\n",
        "    lista_rah.append('rah_corr_{}'.format(rodadas))\n",
        "    lista_u_star_img.append('u_estrela_corr_img_{}'.format(rodadas))    \n",
        "    lista_rah_img.append('rah_corr_img_{}'.format(rodadas))\n",
        " \n",
        "    L = (-1)*1.15*1004*((lista_u_star[0])**3)*p_quente_ok/(0.41*9.81*H)\n",
        " \n",
        "    x_0_1m = ((1-16)*0.1/L)**0.25\n",
        "    x_2m = ((1-16)*2/L)**0.25\n",
        "    x_200m = ((1-16)*200/L)**0.25\n",
        " \n",
        "    psi_h0_1 = 2*np.log((1+(x_0_1m**2))/2)\n",
        "    psi_h2 = 2*np.log((1+(x_2m**2))/2)\n",
        "    psi_m200 = 2*np.log((1+x_200m)/2)+np.log((1+x_200m**2)/2)-2*np.arctan(x_200m)+0.5*np.pi\n",
        " \n",
        "    lista_u_star[1] = u200*0.41/((np.log(200/zom))-psi_m200)\n",
        "    lista_rah[1] = (np.log(2/0.1)-psi_h2+psi_h0_1)/(0.41*(lista_u_star[1]))\n",
        "    b_corr = (rn_quente - g_quente)*lista_rah[1] / (1.15*1004*(p_quente_ok - p_frio_ok))\n",
        "    a_corr = (-1)*b_corr*(p_frio_ok - 273.15)\n",
        " \n",
        "    H = 1.15 * 1004 * (a_corr + (b_corr * (p_quente_ok - 273.15)))/lista_rah[1]\n",
        " \n",
        "    #calculando nas imagens:\n",
        "    L_img = (-1)*1.15*1004*(((lista_u_star_img[0]))**3)*tsup/(0.41*9.81*H_corr_img)\n",
        "    x_0_1m_img = ((1-16)*0.1/L_img)**0.25\n",
        "    x_2m_img = ((1-16)*2/L_img)**0.25\n",
        "    x_200m_img = ((1-16)*200/L_img)**0.25\n",
        " \n",
        "    psi_h0_1_img_c = np.where(L_img < 0.0, 2*np.log((1+(x_0_1m_img**2))/2), (-1)*5*(0.1/L_img))\n",
        "    psi_h2_img_c = np.where(L_img < 0.0, 2*np.log((1+(x_2m_img**2))/2), (-1)*5*(2/L_img))\n",
        "    psi_m200_img_c = np.where(L_img < 0.0, 2*np.log((1+x_200m_img)/2)+np.log((1+(x_200m_img**2))/2)-(2*np.arctan(x_200m_img))+0.5*(np.pi),\n",
        "                              (-1)*5*(200/L_img))\n",
        "    lista_u_star_img[1] = (u200*0.41)/((np.log(200/zom_img))-psi_m200_img_c)\n",
        "    lista_rah_img[1] = (np.log(2/0.1)-psi_h2_img_c+psi_h0_1_img_c)/(0.41 * lista_u_star_img[1])\n",
        "    H_corr_img = 1.15 * 1004 * (a_corr + (b_corr * (tsup - 273.15)))/lista_rah_img[1]\n",
        "    \n",
        "    err_rel = abs(lista_rah[1] - lista_rah[0])*100/lista_rah[1]\n",
        "    print('Rodada',rodadas,' a vale: ', a_corr, 'b vale: ', b_corr, 'O Erro relativo é: ', err_rel)\n",
        "    print ('H é: ', H)\n",
        " \n",
        "    #excluíndo o primeiro ítem de cada lista\n",
        "    lista_u_star.pop(0)\n",
        "    lista_rah.pop(0)\n",
        "    lista_u_star_img.pop(0)\n",
        "    lista_rah_img.pop(0)\n",
        " \n",
        "print('Fim do processo, a vale: ', a_corr, 'b vale: ', b_corr, 'O Erro relativo é: ', err_rel)\n",
        " \n",
        "#//Calculando o Fluxo de calor latente (LE) e a ET_24h\n",
        " \n",
        "LE = rn - g_corrigido - H_corr_img\n",
        "LE = np.where(LE < 0.0, 0.0, LE)\n",
        "fe = LE / (rn - g_corrigido)\n",
        " \n",
        "del_ = 0.409*np.sin(2*np.pi*DOA/(365-1.39))\n",
        "fi = lat * np.pi/180\n",
        "H_hor = np.arccos(-np.tan(fi)*np.tan(del_))\n",
        "rs_24_toa = 118.08*dr*(H_hor*np.sin(fi)*np.sin(del_)+np.cos(fi)*np.cos(del_)*np.sin(H_hor))/np.pi\n",
        "print('Rs_TOA é: ', rs_24_toa)\n",
        " \n",
        "tsw_24 = rs_24 / rs_24_toa\n",
        "print('tsw_24 é: ', tsw_24)\n",
        " \n",
        "rn_24 = (1-albedo)*rs_24*11.57407 - 110*tsw_24 #//Rs_24 transformado em W/m²\n",
        " \n",
        "#print('LE é: ', LE)\n",
        "ET_24 = 0.0353*fe*rn_24\n",
        "ET_24 = np.ma.masked_where(ET_24 < 0, ET_24)\n",
        "ET_24 = ET_24.filled(-99)\n",
        " \n",
        "f1_frio = f1_frio.filled(-99)\n",
        "out_ds = make_raster(albedo_open, 'le', LE, gdal.GDT_Float32, -99)\n",
        "#out_ds = make_raster(albedo_open, 'le', LE, gdal.GDT_Float32, -99)\n",
        "#out_ds = make_raster(albedo_open, export_ndvi, ndvi, gdal.GDT_Float32, -99)\n",
        "out_ds = make_raster(albedo_open, 'g', g_corrigido, gdal.GDT_Float32, -99)\n",
        "out_ds = make_raster(albedo_open, 'rn', rn, gdal.GDT_Float32, -99)\n",
        "out_ds = make_raster(albedo_open, 'h', H_corr_img, gdal.GDT_Float32, -99)\n",
        "out_ds = make_raster(albedo_open, export_et24, ET_24, gdal.GDT_Float32, -99)\n",
        " \n",
        "del out_ds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0613773239067819\n",
            "dr é:  1.03505\n",
            "Cos(z) é:  0.919720361134887\n",
            "elevacao é:  66.88523482351987\n",
            "e_a equivale a :  1.6377583583068727\n",
            "w equivale a :  22.185603806054523\n",
            "transmitancia equivale a :  0.7613093073560777\n",
            "a radiação global é:  990.7105429937882\n",
            "a radiação atm é:  396.1995749394879\n",
            "Esse é o percentil 95 do NDVI  0.9246758357562967\n",
            "esse é o percentil 20 da Tsup:  298.6078002929687\n",
            "albedo chave é:  0.18313208761022004\n",
            "Esse é o pixel frio do CIMEC:  297.18829345703125\n",
            "Esse é o pixel quente do CIMEC:  306.60516357421875\n",
            "O savi do Pixel quente é:  0.029252122787584982\n",
            "O Rn do Pixel quente é:  751.9114780422176\n",
            "O G do Pixel quente é:  225.57344341266528\n",
            "O Fluxo de calor sensível H é:  526.3380346295521\n",
            "Rn - G é:  526.3380346295523\n",
            "a vale:  -7.221938765473871 b vale:  0.3004347533398396 O Erro relativo é:  85.41619996702153\n",
            "H é:  526.3380346295523\n",
            "Rodada 2  a vale:  -15.980556746113937 b vale:  0.664795809015285 O Erro relativo é:  54.80796520290157\n",
            "H é:  526.3380346295525\n",
            "Rodada 3  a vale:  -12.21328586243625 b vale:  0.508076244441713 O Erro relativo é:  30.845678436664432\n",
            "H é:  526.3380346295521\n",
            "Rodada 4  a vale:  -13.4388528516599 b vale:  0.5590601876827074 O Erro relativo é:  9.119580389424925\n",
            "H é:  526.3380346295522\n",
            "Rodada 5  a vale:  -12.998473141991116 b vale:  0.5407402636641423 O Erro relativo é:  3.3879341431737244\n",
            "H é:  526.3380346295522\n",
            "Rodada 6  a vale:  -13.151287800907884 b vale:  0.5470973979253545 O Erro relativo é:  1.1619748668736283\n",
            "H é:  526.3380346295525\n",
            "Fim do processo, a vale:  -13.151287800907884 b vale:  0.5470973979253545 O Erro relativo é:  1.1619748668736283\n",
            "Rs_TOA é:  38.21269783545243\n",
            "tsw_24 é:  0.6882528973287974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:121: RuntimeWarning: invalid value encountered in log\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8hxPhDLvqFD"
      },
      "source": [
        "########################################################       DICAS     #######################################\n",
        "#Reducer no GEE:\n",
        "var cos_z_red = cos_z_img.reduceRegion({\n",
        "  reducer: ee.Reducer.mean(),\n",
        "  geometry: area,\n",
        "  scale: 30\n",
        "});\n",
        "#Reducer no python\n",
        "cos_z_red = cos_z_img.reduceRegion(\n",
        "  ee.Reducer.mean(),\n",
        "  area,\n",
        "  30)\n",
        "\n",
        "#pegando um valor do Dict no GEE:\n",
        "var cos_z = cos_z_red.getNumber('SolarZenith');\n",
        "\n",
        "#pegando um valor do Dict no python:\n",
        "cos_z = cos_z_red.getInfo()['SolarZenith']"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}